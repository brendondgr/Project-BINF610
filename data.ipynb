{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edd30fa5",
   "metadata": {},
   "source": [
    "# Overview\n",
    "Dataset from: https://www.kaggle.com/datasets/akshaydattatraykhare/diabetes-dataset\n",
    "\n",
    "### Introduction\n",
    "There are a few methods that I intend to employ within this data. Given that there are only 8 features, there is not much dimensionality within the data. Therefore, more complex models such as neural networks may not be needed.\n",
    "\n",
    "### Methods Selection\n",
    "As such, the following will more than likely be enough to properly synthesize appropriate results:\n",
    "- Logistic Regression: Will allow more interpretable results.\n",
    "- Random Forest/Decision Tree: While the Random Forest may be more accurate, I will utilize both approaches, since these both do well with problems that have a feature count similar to this problem.\n",
    "- Support Vector Machine: Works well with non-linear relationships, which may be found within this data.\n",
    "- Neural Networks: Even though I state this may be overkill, I will test a few networks to see how well they perform to learn how to regulate over- and under-fitting.\n",
    "\n",
    "I will also be employing other methods, such as:\n",
    "- Gradient Boosting (XGBoost): May combine this with techniques to see if there is a data imbalance (I.e. SMOTE & ADASYN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516d6b4e",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c86b072",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Brendito\\anaconda3\\envs\\torch_2\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import kagglehub\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26de909d",
   "metadata": {},
   "source": [
    "### Custom Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "547f7bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.logistic import Logistic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3a2eb2",
   "metadata": {},
   "source": [
    "## Custom Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e8ad728",
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_graphs = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2f21db",
   "metadata": {},
   "source": [
    "## Initialize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf6296cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\Brendito\\.cache\\kagglehub\\datasets\\akshaydattatraykhare\\diabetes-dataset\\versions\\1\n"
     ]
    }
   ],
   "source": [
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"akshaydattatraykhare/diabetes-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f87a568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of df: 768\n"
     ]
    }
   ],
   "source": [
    "# Load the CSV file into a pandas DataFrame\n",
    "csv_file_path = os.path.join(path, \"diabetes.csv\")  # Replace \"diabetes.csv\" with the actual file name\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Get the Length of the DataFrame\n",
    "print(\"Length of df:\", len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1340bd3",
   "metadata": {},
   "source": [
    "## Preprocessing of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7673edf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the columns to check for zero values\n",
    "columns_to_check = [\"Glucose\", \"SkinThickness\", \"BloodPressure\", \"Insulin\", \"BMI\"]\n",
    "\n",
    "# Replace zero values in the specified columns with -1\n",
    "df[columns_to_check] = df[columns_to_check].replace(0, -1)\n",
    "\n",
    "# Name Changes\n",
    "name_changes = {\"BloodPressure\": \"Blood Pressure\", \"SkinThickness\": \"Skin Thickness\", \"DiabetesPedigreeFunction\": \"Diabetes Pedigree Function\", \"BMI\": \"Body Mass Index\", \"Age\": \"Age\", \"Glucose\": \"Glucose\", \"Insulin\": \"Insulin\", \"Pregnancies\": \"Pregnancies\"}\n",
    "# Rename the columns in the DataFrame\n",
    "df.rename(columns=name_changes, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1b69e5",
   "metadata": {},
   "source": [
    "## Data Examination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77db266c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Pregnancies  Glucose  Blood Pressure  Skin Thickness  Insulin  \\\n",
      "0            6      148              72              35       -1   \n",
      "1            1       85              66              29       -1   \n",
      "2            8      183              64              -1       -1   \n",
      "3            1       89              66              23       94   \n",
      "4            0      137              40              35      168   \n",
      "\n",
      "   Body Mass Index  Diabetes Pedigree Function  Age  Outcome  \n",
      "0             33.6                       0.627   50        1  \n",
      "1             26.6                       0.351   31        0  \n",
      "2             23.3                       0.672   32        1  \n",
      "3             28.1                       0.167   21        0  \n",
      "4             43.1                       2.288   33        1  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())  # Display the first few rows of the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b2bbd33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Pregnancies\", \"Glucose\", \"Blood Pressure\", \"Skin Thickness\", \"Insulin\", \"Body Mass Index\", \"Diabetes Pedigree Function\", \"Age\", \"Outcome\"\n",
      "                           Count     Mean      Std    Min     5%    25%  \\\n",
      "Pregnancies                  768    3.845     3.37      0    0.0    1.0   \n",
      "Glucose                      763  121.687   30.536     44   80.0   99.0   \n",
      "Blood Pressure               733   72.405   12.382     24   52.0   64.0   \n",
      "Skin Thickness               541   29.153   10.477      7   13.0   22.0   \n",
      "Insulin                      394  155.548  118.776     14  41.65  76.25   \n",
      "Body Mass Index              757   32.457    6.925   18.2   22.2   27.5   \n",
      "Diabetes Pedigree Function   768    0.472    0.331  0.078   0.14  0.244   \n",
      "Age                          768   33.241    11.76     21   21.0   24.0   \n",
      "Outcome                      768    0.349    0.477      0    0.0    0.0   \n",
      "\n",
      "                           Median    75%    95%   Max  \n",
      "Pregnancies                   3.0    6.0   10.0    17  \n",
      "Glucose                     117.0  141.0  181.0   199  \n",
      "Blood Pressure               72.0   80.0   92.0   122  \n",
      "Skin Thickness               29.0   36.0   46.0    99  \n",
      "Insulin                     125.0  190.0  395.5   846  \n",
      "Body Mass Index              32.3   36.6   44.5  67.1  \n",
      "Diabetes Pedigree Function  0.372  0.626  1.133  2.42  \n",
      "Age                          29.0   41.0   58.0    81  \n",
      "Outcome                       0.0    1.0    1.0     1  \n"
     ]
    }
   ],
   "source": [
    "# Create empty DataFrame to store statistics\n",
    "columns = ['Count', 'Mean', 'Std', 'Min', '5%', '25%', 'Median', '75%', '95%', 'Max']\n",
    "stats_df = pd.DataFrame(index=df.columns, columns=columns)\n",
    "\n",
    "# Calculate statistics for each column\n",
    "for column in df.columns:\n",
    "    # Filter out the -1 values\n",
    "    filtered_data = df[df[column] != -1][column]\n",
    "    \n",
    "    # Places to round to\n",
    "    round_to = 3\n",
    "    \n",
    "    # Calculate statistics\n",
    "    stats_df.loc[column, 'Count'] = filtered_data.count()\n",
    "    stats_df.loc[column, 'Mean'] = round(filtered_data.mean(), round_to)\n",
    "    stats_df.loc[column, 'Std'] = round(filtered_data.std(), round_to)\n",
    "    stats_df.loc[column, 'Min'] = round(filtered_data.min(), round_to)\n",
    "    stats_df.loc[column, '5%'] = round(filtered_data.quantile(0.05), round_to)\n",
    "    stats_df.loc[column, '25%'] = round(filtered_data.quantile(0.25), round_to)\n",
    "    stats_df.loc[column, 'Median'] = round(filtered_data.median(), round_to)\n",
    "    stats_df.loc[column, '75%'] = round(filtered_data.quantile(0.75), round_to)\n",
    "    stats_df.loc[column, '95%'] = round(filtered_data.quantile(0.95), round_to)\n",
    "    stats_df.loc[column, 'Max'] = round(filtered_data.max(), round_to)\n",
    "\n",
    "print(\", \".join(f'\"{column}\"' for column in df.columns))\n",
    "\n",
    "print(stats_df)\n",
    "\n",
    "# Round to 2 decimal places and save as csv\n",
    "stats_df.to_csv(\"diabetes_stats.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebee8a4",
   "metadata": {},
   "source": [
    "### Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "296928c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping Graphs since skip_graphs is set to True\n"
     ]
    }
   ],
   "source": [
    "if not skip_graphs:\n",
    "    # Create a 3x3 grid of histograms using Seaborn\n",
    "    fig, axes = plt.subplots(3, 3, figsize=(15, 15))\n",
    "    axes = axes.ravel()  # Flatten the 3x3 array of axes for easier iteration\n",
    "\n",
    "    # Dictionary of Name Changes\n",
    "    x_labels = {\"Blood Pressure\": \"Blood Pressure (mmHg)\", \"Skin Thickness\": \"Skin Thickness (dm)\", \"Diabetes Pedigree Function\": \"Diabetes Pedigree Function\", \"Body Mass Index\": \"Body Mass Index\", \"Age\": \"Age\", \"Glucose\": \"Glucose (mg/dL)\", \"Insulin\": \"Insulin (pmol/L)\", \"Pregnancies\": \"Pregnancies (#)\"}\n",
    "\n",
    "    # Plot each column in the DataFrame\n",
    "    for i, column in enumerate(df.columns):\n",
    "        # Filter out values that are -1\n",
    "        filtered_data = df[df[column] != -1][column]\n",
    "        \n",
    "        # Create histogram without KDE line\n",
    "        sns.histplot(data=filtered_data, bins=8, kde=False, ax=axes[i], color='skyblue', edgecolor='black')\n",
    "        \n",
    "        # Add statistical markers\n",
    "        median = filtered_data.median()\n",
    "        q1 = filtered_data.quantile(0.05)\n",
    "        q3 = filtered_data.quantile(0.95)\n",
    "        mean = filtered_data.mean()\n",
    "        axes[i].axvline(q1, color='black', linestyle='dotted', linewidth=1, label=f'5%: {q1:.2f}')\n",
    "        axes[i].axvline(median, color='red', linestyle='dashed', linewidth=1, label=f'Median: {median:.2f}')\n",
    "        axes[i].axvline(mean, color='green', linestyle='dashed', linewidth=1, label=f'Mean: {mean:.2f}')\n",
    "        axes[i].axvline(q3, color='purple', linestyle='dotted', linewidth=1, label=f'95%: {q3:.2f}')\n",
    "        \n",
    "        # Set titles and labels\n",
    "        title = f\"{name_changes.get(column, column)}\"\n",
    "        axes[i].set_title(title)\n",
    "        axes[i].set_xlabel(x_labels.get(column, column))\n",
    "        axes[i].set_ylabel('Frequency')\n",
    "        axes[i].legend()\n",
    "\n",
    "    # Adjust layout to prevent overlap\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Skipping Graphs since skip_graphs is set to True\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78f448b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping Graphs since skip_graphs is set to True\n"
     ]
    }
   ],
   "source": [
    "if not skip_graphs:\n",
    "    # Create a 3x3 grid for KDE plots\n",
    "    fig, axes = plt.subplots(3, 3, figsize=(15, 15))\n",
    "    axes = axes.ravel()  # Flatten the 3x3 array of axes for easier iteration\n",
    "    \n",
    "    # Plot KDE for each column\n",
    "    for i, column in enumerate(df.columns):\n",
    "        # Filter out values that are -1\n",
    "        filtered_data = df[df[column] != -1][column]\n",
    "        sns.kdeplot(data=filtered_data, ax=axes[i], fill=True, color='skyblue', bw_adjust=1, label='KDE')\n",
    "        axes[i].set_title(f\"{name_changes.get(column, column)}\")\n",
    "        axes[i].set_xlabel(column)\n",
    "        axes[i].set_ylabel('Density')\n",
    "        # axes[i].legend()\n",
    "\n",
    "    # Adjust layout to prevent overlap\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Skipping Graphs since skip_graphs is set to True\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da83f3a5",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bc5926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "       Accuracy  Precision    Recall        F1   ROC AUC\n",
      "Train  0.700186   0.614035  0.374332  0.465116  0.696134\n",
      "Test   0.692641   0.586207  0.419753  0.489209  0.664691\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "       Accuracy  Precision    Recall        F1   ROC AUC\n",
      "Train  0.713222   0.636364  0.411765  0.500000  0.695569\n",
      "Test   0.688312   0.573770  0.432099  0.492958  0.659753\n",
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    }
   ],
   "source": [
    "models_logistic = [\n",
    "    Logistic(penalty=\"l1\"),\n",
    "    Logistic(penalty=\"l2\"),\n",
    "    Logistic(penalty=\"elasticnet\")\n",
    "]\n",
    "\n",
    "names = [\"L1\", \"L2\", \"Elasticnet\"]\n",
    "\n",
    "for model, name in zip(models_logistic, names):\n",
    "    # Print Name of Current Run.\n",
    "    print(f\"Running {name}...\")\n",
    "    \n",
    "    # Get the Train, Test Sets\n",
    "    X_train, X_test, y_train, y_test = model.split_train_test(df)\n",
    "    \n",
    "    # Run the model\n",
    "    results = model.train_and_evaluate(X_train, X_test, y_train, y_test)\n",
    "    print(results)\n",
    "    \n",
    "    # Save results to CSV\n",
    "    results.to_csv(f\"logistic_{name}_results.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
